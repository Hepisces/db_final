import streamlit as st
import pandas as pd
import sqlite3
from contextlib import closing
import random
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
import sqlparse
import graphviz

# --- Database Setup and Mock Data Generation ---

DB_FILE = "visualization_demo.db"

def create_connection():
    """Create a database connection to the SQLite database."""
    return sqlite3.connect(DB_FILE)

def create_tables(conn):
    """Create tables based on the provided DDL."""
    ddl_script = """
    CREATE TABLE IF NOT EXISTS customer (
        uid   VARCHAR NOT NULL PRIMARY KEY,
        label INTEGER
    );

    CREATE TABLE IF NOT EXISTS devlist (
        uid  VARCHAR REFERENCES customer(uid) ON DELETE SET NULL,
        did  VARCHAR NOT NULL PRIMARY KEY,
        type VARCHAR,
        area VARCHAR
    );

    CREATE TABLE IF NOT EXISTS control (
        uid  VARCHAR,
        did  VARCHAR NOT NULL,
        form VARCHAR NOT NULL,
        data VARCHAR NOT NULL,
        time TIMESTAMP NOT NULL,
        PRIMARY KEY (did, time, form, data),
        FOREIGN KEY (uid) REFERENCES customer(uid)
    );

    CREATE TABLE IF NOT EXISTS devupdata (
        uid  VARCHAR,
        did  VARCHAR NOT NULL,
        time TIMESTAMP NOT NULL,
        data VARCHAR NOT NULL,
        PRIMARY KEY (did, time, data),
        FOREIGN KEY (uid) REFERENCES customer(uid)
    );
    """
    with closing(conn.cursor()) as cursor:
        cursor.executescript(ddl_script)
    conn.commit()

def generate_mock_data(conn, num_customers=10, num_devices_per_customer=3, num_events_per_device=100):
    """Generate and insert mock data into the database."""
    cursor = conn.cursor()

    # Check if data exists
    cursor.execute("SELECT COUNT(*) FROM customer")
    if cursor.fetchone()[0] > 0:
        st.info("æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆã€‚")
        return

    st.info("æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")

    # Customers
    customers = []
    for i in range(num_customers):
        uid = f"user_{i:03d}"
        customers.append((uid, random.randint(1, 5)))
    cursor.executemany("INSERT INTO customer (uid, label) VALUES (?, ?)", customers)

    # Devices
    devices = []
    device_types = ['light', 'thermostat', 'camera', 'lock', 'sensor']
    areas = ['living_room', 'bedroom', 'kitchen', 'bathroom', 'office']
    device_id_counter = 0
    for uid, _ in customers:
        for _ in range(num_devices_per_customer):
            did = f"device_{device_id_counter:04d}"
            devices.append((uid, did, random.choice(device_types), random.choice(areas)))
            device_id_counter += 1
    cursor.executemany("INSERT INTO devlist (uid, did, type, area) VALUES (?, ?, ?, ?)", devices)

    # Control and DevUpdate Events
    control_events = []
    devupdata_events = []
    now = datetime.now()

    for uid, did, dev_type, area in devices:
        for i in range(num_events_per_device):
            event_time = now - timedelta(days=random.randint(0, 30), hours=random.randint(0, 23))
            
            # Control events
            form = random.choice(['app', 'voice', 'auto'])
            if dev_type == 'light':
                data = random.choice(['on', 'off', f"brightness_{random.randint(10,100)}"])
            elif dev_type == 'thermostat':
                data = f"temp_{random.uniform(18.0, 25.0):.1f}"
            else:
                data = random.choice(['locked', 'unlocked', 'recording_on'])
            control_events.append((uid, did, form, data, event_time))
            
            # DevUpdate events (e.g., sensor readings)
            if dev_type in ['thermostat', 'sensor', 'camera']:
                 update_data = f"status_{random.choice(['ok', 'offline', 'triggered'])}_{random.random():.2f}"
                 devupdata_events.append((uid, did, event_time, update_data))


    cursor.executemany("INSERT INTO control (uid, did, form, data, time) VALUES (?, ?, ?, ?, ?)", control_events)
    cursor.executemany("INSERT INTO devupdata (uid, did, time, data) VALUES (?, ?, ?, ?)", devupdata_events)

    conn.commit()
    st.success("æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå®Œæ¯•ï¼")

# --- Main App Logic ---

def main():
    st.set_page_config(page_title="SQLæŸ¥è¯¢å¯è§†åŒ–Demo", layout="wide")
    st.title("ğŸ—‚ï¸ SQL æŸ¥è¯¢ä¸å¯è§†åŒ–å¹³å°")
    
    # Initialize database
    conn = create_connection()
    create_tables(conn)
    generate_mock_data(conn)
    
    st.sidebar.header("æ•°æ®åº“ Schema")
    st.sidebar.code("""
    customer(uid, label)
    devlist(uid, did, type, area)
    control(uid, did, form, data, time)
    devupdata(uid, did, time, data)
    """, language="sql")
    
    st.sidebar.header("ç¤ºä¾‹æŸ¥è¯¢")
    example_queries = {
        "æ—¶åºæ•°æ®: æœ€è¿‘ä¸€å°æ—¶çš„è®¾å¤‡æ§åˆ¶è®°å½•": "SELECT * FROM control WHERE time >= datetime('now', '-1 hour') ORDER BY time DESC;",
        "GROUP BY: å„åŒºåŸŸè®¾å¤‡æ•°é‡ç»Ÿè®¡": "SELECT area, COUNT(did) as device_count FROM devlist GROUP BY area;",
        "JOIN: æŸ¥è¯¢ç”¨æˆ·'user_001'çš„è®¾å¤‡åŠå…¶ç±»å‹": "SELECT c.uid, d.did, d.type, d.area FROM customer c JOIN devlist d ON c.uid = d.uid WHERE c.uid = 'user_001';",
        "å¤æ‚èšåˆ: ä¸åŒè®¾å¤‡ç±»å‹æ¯å¤©çš„å¹³å‡æ§åˆ¶æ¬¡æ•°": "SELECT d.type, DATE(c.time) as day, COUNT(c.did) as control_count FROM control c JOIN devlist d ON c.did = d.did GROUP BY d.type, day ORDER BY day, control_count DESC;"
    }
    
    query_choice = st.sidebar.selectbox("é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹æˆ–åœ¨ä¸‹æ–¹è¾“å…¥è‡ªå®šä¹‰æŸ¥è¯¢", options=list(example_queries.keys()), index=0)
    
    query_input = st.text_area("SQL æŸ¥è¯¢", value=example_queries[query_choice], height=150)

    if st.button("ğŸš€ æ‰§è¡ŒæŸ¥è¯¢å¹¶å¯è§†åŒ–"):
        if query_input:
            try:
                # --- Query Plan Visualization ---
                st.subheader("ğŸ“Š æŸ¥è¯¢è®¡åˆ’ (Query Plan)")
                with st.spinner("ç”ŸæˆæŸ¥è¯¢è®¡åˆ’..."):
                    plan_df = get_query_plan(conn, query_input)
                    plan_graph = create_plan_graph(plan_df)
                    st.graphviz_chart(plan_graph)
                
                # --- Query Result Visualization ---
                st.subheader("ğŸ“ˆ æŸ¥è¯¢ç»“æœ")
                result_df, description = execute_query(conn, query_input)
                
                if not result_df.empty:
                    st.dataframe(result_df)
                    visualize_results(query_input, result_df)
                else:
                    st.info("æŸ¥è¯¢æˆåŠŸï¼Œä½†æ²¡æœ‰è¿”å›ä»»ä½•æ•°æ®ã€‚")

            except Exception as e:
                st.error(f"æŸ¥è¯¢æ‰§è¡Œå‡ºé”™: {e}")
        else:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„SQLæŸ¥è¯¢ã€‚")

    conn.close()

def execute_query(conn, query):
    """Execute a SQL query and return the result as a DataFrame."""
    df = pd.read_sql_query(query, conn)
    cursor = conn.cursor()
    cursor.execute(query)
    description = [desc[0] for desc in cursor.description]
    return df, description

def get_query_plan(conn, query):
    """Get the query plan for a SQL query."""
    plan_query = f"EXPLAIN QUERY PLAN {query}"
    plan_df = pd.read_sql_query(plan_query, conn)
    return plan_df

def create_plan_graph(plan_df):
    """Create a graphviz Digraph from the query plan DataFrame."""
    graph = graphviz.Digraph('query_plan', node_attr={'shape': 'record'})
    
    for index, row in plan_df.iterrows():
        node_id = str(row['id'])
        detail = row['detail'].replace('<', '&lt;').replace('>', '&gt;')
        label = f"{{<f0>ID: {row['id']} | {detail}}}"
        graph.node(node_id, label)
        
        parent_id = str(row['parent'])
        if parent_id != '0':
            graph.edge(parent_id, node_id)
            
    return graph

def visualize_results(query, df):
    """Infer query type and visualize results."""
    
    query_type = infer_query_type(query, df)
    st.write(f"è‡ªåŠ¨æ¨æ–­çš„æŸ¥è¯¢ç±»å‹: **{query_type}**")

    if query_type == "æ—¶é—´åºåˆ—":
        visualize_time_series(df)
    elif query_type == "èšåˆåˆ†æ":
        visualize_aggregation(df)
    elif query_type == "ç±»åˆ«åˆ†å¸ƒ":
        visualize_categorical(df)
    else:
        st.write("é»˜è®¤ä½¿ç”¨è¡¨æ ¼å±•ç¤ºã€‚å¯å°è¯•ä¿®æ”¹æŸ¥è¯¢ä»¥è·å¾—æ›´ä¸°å¯Œçš„å¯è§†åŒ–æ•ˆæœã€‚")

def infer_query_type(query, df):
    """Infer query type to select a suitable visualization method."""
    formatted_query = sqlparse.format(query.strip(), keyword_case='upper')
    
    # Time Series
    time_cols = [c for c in df.columns if 'time' in c.lower() or 'date' in c.lower()]
    if any(pd.api.types.is_datetime64_any_dtype(df[c]) for c in time_cols):
        return "æ—¶é—´åºåˆ—"
    if time_cols and len(df[time_cols[0]].unique()) > 1:
        return "æ—¶é—´åºåˆ—"

    # Aggregation
    if 'GROUP BY' in formatted_query:
        return "èšåˆåˆ†æ"
    
    agg_funcs = ['COUNT(', 'SUM(', 'AVG(', 'MIN(', 'MAX(']
    if any(func in formatted_query for func in agg_funcs):
         return "èšåˆåˆ†æ"
         
    # Categorical
    if len(df.columns) == 2 and pd.api.types.is_numeric_dtype(df.iloc[:, 1]) and pd.api.types.is_string_dtype(df.iloc[:, 0]):
        return "ç±»åˆ«åˆ†å¸ƒ"

    return "ä¸€èˆ¬æŸ¥è¯¢"


def visualize_time_series(df):
    """Visualize time series data with a line chart."""
    time_col = None
    for col in df.columns:
        if 'time' in col.lower() or 'date' in col.lower():
            try:
                df[col] = pd.to_datetime(df[col])
                time_col = col
                break
            except (ValueError, TypeError):
                continue

    if not time_col:
        st.warning("æœªæ‰¾åˆ°å¯è§£æä¸ºæ—¶é—´åºåˆ—çš„åˆ—ã€‚")
        return

    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    if not numeric_cols:
        st.warning("æ—¶é—´åºåˆ—æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°æ•°å€¼åˆ—ç”¨äºç»˜å›¾ã€‚")
        return

    st.write("#### æ—¶é—´åºåˆ—åˆ†æ")
    y_axis_options = numeric_cols
    y_axis = st.selectbox("é€‰æ‹©Yè½´æ•°æ®", options=y_axis_options)

    if y_axis:
        fig = px.line(df, x=time_col, y=y_axis, title=f"{y_axis} aæ—¶é—´è¶‹åŠ¿", markers=True)
        fig.update_layout(xaxis_title="æ—¶é—´", yaxis_title=y_axis)
        st.plotly_chart(fig, use_container_width=True)

def visualize_aggregation(df):
    """Visualize aggregation results with bar or pie charts."""
    st.write("#### èšåˆåˆ†æ")
    
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()

    if not numeric_cols or not categorical_cols:
        st.warning("èšåˆåˆ†æéœ€è¦è‡³å°‘ä¸€ä¸ªç±»åˆ«åˆ—å’Œä¸€ä¸ªæ•°å€¼åˆ—ã€‚")
        return
        
    category_col = st.selectbox("é€‰æ‹©ç±»åˆ«åˆ— (Xè½´)", options=categorical_cols)
    metric_col = st.selectbox("é€‰æ‹©æ•°å€¼åˆ— (Yè½´)", options=numeric_cols)

    if len(df) <= 15:
        chart_type = st.radio("é€‰æ‹©å›¾è¡¨ç±»å‹", ('æ¡å½¢å›¾', 'é¥¼å›¾'))
        if chart_type == 'é¥¼å›¾':
            fig = px.pie(df, names=category_col, values=metric_col, title=f"{metric_col} æŒ‰ {category_col} åˆ†å¸ƒ")
        else:
            fig = px.bar(df, x=category_col, y=metric_col, title=f"{metric_col} æŒ‰ {category_col} å¯¹æ¯”")
    else:
        st.info("æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨æ¡å½¢å›¾ã€‚")
        fig = px.bar(df, x=category_col, y=metric_col, title=f"{metric_col} æŒ‰ {category_col} å¯¹æ¯”")
    
    st.plotly_chart(fig, use_container_width=True)

def visualize_categorical(df):
    """Visualize categorical distribution."""
    st.write("#### ç±»åˆ«åˆ†å¸ƒ")
    category_col = df.columns[0]
    metric_col = df.columns[1]

    if len(df) <= 15:
        chart_type = st.radio("é€‰æ‹©å›¾è¡¨ç±»å‹", ('æ¡å½¢å›¾', 'é¥¼å›¾'))
        if chart_type == 'é¥¼å›¾':
            fig = px.pie(df, names=category_col, values=metric_col, title=f"{metric_col} æŒ‰ {category_col} åˆ†å¸ƒ")
        else:
            fig = px.bar(df, x=category_col, y=metric_col, title=f"{metric_col} æŒ‰ {category_col} å¯¹æ¯”")
    else:
        st.info("æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨æ¡å½¢å›¾ã€‚")
        fig = px.bar(df, x=category_col, y=metric_col, title=f"{metric_col} æŒ‰ {category_col} å¯¹æ¯”")
    
    st.plotly_chart(fig, use_container_width=True)


if __name__ == "__main__":
    main() 