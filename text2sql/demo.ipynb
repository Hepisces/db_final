{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# 忽略特定的警告\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Torch was not compiled with flash attention.*\")\n",
    "\n",
    "def load_sqlcoder_fixed():\n",
    "    \"\"\"\n",
    "    修复版本的SQLCoder模型加载，使用自定义下载路径\n",
    "    \"\"\"\n",
    "    print(\"正在加载SQLCoder模型...\")\n",
    "    \n",
    "    try:\n",
    "        # 设置自定义下载路径\n",
    "        model_path = r\"models--defog--sqlcoder-7b-2\\snapshots\\7e5b6f7981c0aa7d143f6bec6fa26625bdfcbe66\"\n",
    "        print(f\"从本地路径 {model_path} 加载模型...\")\n",
    "        \n",
    "        # 修改tokenizer配置\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path,\n",
    "            trust_remote_code=True,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        \n",
    "        # 显式设置pad_token和pad_token_id\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "        \n",
    "        # 优化模型加载配置\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\",\n",
    "            local_files_only=True,\n",
    "            use_flash_attention_2=False,  # 禁用flash attention\n",
    "            low_cpu_mem_usage=True  # 优化内存使用\n",
    "        )\n",
    "        \n",
    "        # 确保模型的pad_token_id与tokenizer一致\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "        \n",
    "        # 设置模型为评估模式\n",
    "        model.eval()\n",
    "        \n",
    "        print(\"✅ 模型加载成功!\")\n",
    "        return tokenizer, model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 模型加载失败: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def generate_sql_sqlcoder(sqlcoder_tokenizer, sqlcoder_model, question, schema=\"\"):\n",
    "    \"\"\"\n",
    "    使用SQLCoder生成SQL，优化生成过程\n",
    "    \n",
    "    Args:\n",
    "        question: 自然语言问题\n",
    "        schema: 数据库表结构（可选）\n",
    "    \"\"\"\n",
    "    if sqlcoder_tokenizer is None or sqlcoder_model is None:\n",
    "        return \"模型未正确加载\"\n",
    "    \n",
    "    # 构建prompt\n",
    "    if schema:\n",
    "        prompt = f\"### Task\\nGenerate a SQL query to answer this question: {question}\\n\\n### Database Schema\\n{schema}\\n\\n### SQL\\n\"\n",
    "    else:\n",
    "        prompt = f\"### Task\\nGenerate a SQL query to answer this question: {question}\\n\\n### SQL\\n\"\n",
    "    \n",
    "    try:\n",
    "        # 编码输入并添加attention mask\n",
    "        inputs = sqlcoder_tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=False,  # 保持padding为False\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        \n",
    "        # 将输入移动到正确的设备\n",
    "        device = next(sqlcoder_model.parameters()).device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # 生成SQL\n",
    "        with torch.no_grad(), torch.amp.autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):  # 使用自动混合精度\n",
    "            outputs = sqlcoder_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=150,\n",
    "                temperature=0.1,\n",
    "                do_sample=True,\n",
    "                pad_token_id=sqlcoder_tokenizer.pad_token_id,\n",
    "                eos_token_id=sqlcoder_tokenizer.eos_token_id,\n",
    "                num_return_sequences=1,\n",
    "                repetition_penalty=1.2,\n",
    "                use_cache=True  # 启用KV缓存\n",
    "            )\n",
    "        \n",
    "        # 解码结果\n",
    "        full_response = sqlcoder_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 提取SQL部分\n",
    "        if \"### SQL\" in full_response:\n",
    "            sql = full_response.split(\"### SQL\")[-1].strip()\n",
    "        else:\n",
    "            sql = full_response[len(prompt):].strip()\n",
    "        \n",
    "        return sql\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"生成SQL时出错: {e}\")\n",
    "        return f\"生成失败: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载SQLCoder模型...\n",
      "从本地路径 models--defog--sqlcoder-7b-2\\snapshots\\7e5b6f7981c0aa7d143f6bec6fa26625bdfcbe66 加载模型...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3181a1ada8da42728e5132cd0a6c84de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型加载成功!\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "sqlcoder_tokenizer, sqlcoder_model = load_sqlcoder_fixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: \n",
      "找出所有从不点任何东西的顾客。\n",
      "\n",
      "以 任意顺序 返回结果表。\n",
      "\n",
      "结果格式如下所示。\n",
      "\n",
      "\n",
      "\n",
      "示例 1：\n",
      "\n",
      "输入：\n",
      "Customers table:\n",
      "+----+-------+\n",
      "| id | name  |\n",
      "+----+-------+\n",
      "| 1  | Joe   |\n",
      "| 2  | Henry |\n",
      "| 3  | Sam   |\n",
      "| 4  | Max   |\n",
      "+----+-------+\n",
      "Orders table:\n",
      "+----+------------+\n",
      "| id | customerId |\n",
      "+----+------------+\n",
      "| 1  | 3          |\n",
      "| 2  | 1          |\n",
      "+----+------------+\n",
      "输出：\n",
      "+-----------+\n",
      "| Customers |\n",
      "+-----------+\n",
      "| Henry     |\n",
      "| Max       |\n",
      "+-----------+\n",
      "\n",
      "SQL: SELECT c.name FROM Customers c LEFT JOIN Orders o ON c.id = o.customerId WHERE o.customerId IS NULL ORDER BY c.name NULLS LAST\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "if sqlcoder_tokenizer and sqlcoder_model:\n",
    "    # 带表结构的测试\n",
    "    with open('schema.txt', 'r') as f:\n",
    "        schema = f.read()\n",
    "\n",
    "    test_q2 = \"\"\"\n",
    "找出所有从不点任何东西的顾客。\n",
    "\n",
    "以 任意顺序 返回结果表。\n",
    "\n",
    "结果格式如下所示。\n",
    "\n",
    "\n",
    "\n",
    "示例 1：\n",
    "\n",
    "输入：\n",
    "Customers table:\n",
    "+----+-------+\n",
    "| id | name  |\n",
    "+----+-------+\n",
    "| 1  | Joe   |\n",
    "| 2  | Henry |\n",
    "| 3  | Sam   |\n",
    "| 4  | Max   |\n",
    "+----+-------+\n",
    "Orders table:\n",
    "+----+------------+\n",
    "| id | customerId |\n",
    "+----+------------+\n",
    "| 1  | 3          |\n",
    "| 2  | 1          |\n",
    "+----+------------+\n",
    "输出：\n",
    "+-----------+\n",
    "| Customers |\n",
    "+-----------+\n",
    "| Henry     |\n",
    "| Max       |\n",
    "+-----------+\n",
    "\"\"\"\n",
    "    result2 = generate_sql_sqlcoder(sqlcoder_tokenizer, sqlcoder_model, test_q2, schema)\n",
    "    print(f\"问题: {test_q2}\")\n",
    "    print(f\"SQL: {result2}\")\n",
    "else:\n",
    "    print(\"❌ 模型加载失败，无法进行测试\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
